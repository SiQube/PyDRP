{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322b00c5-5062-4ef8-ab19-c4438080605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.multi_pred import DTI\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from PyDRP.Data.features.targets import MinMaxScaling\n",
    "from PyDRP.Data.features.drugs import GraphCreator\n",
    "from PyDRP.Data.features.proteins import BertProteinFeaturizer\n",
    "from PyDRP.Data import DTIDatasetManager, TDCDTIWrapper\n",
    "from PyDRP.Data.utils import TorchProteinsGraphsDataset\n",
    "from PyDRP.Models.PairsNetwork import PairsNetwork\n",
    "from PyDRP.Models.encoders.drugs import GATmannEncoder\n",
    "from PyDRP.Models.encoders.cells import GeneExpEncoder\n",
    "from PyDRP.Models.decoders import FCDecoder,  NonlinearDotDecoder\n",
    "from PyDRP.Models.NNlayers import AttnDropout\n",
    "from  PyDRP.Models.NNlayers import TransGAT, GatedGNNRes\n",
    "import pandas as pd\n",
    "import torch_geometric\n",
    "from torch import nn\n",
    "from torch_geometric import nn as gnn\n",
    "import torchmetrics\n",
    "from PyDRP.Models.metrics import ElementwiseMetric\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f86681-ba26-4cf4-859e-27dd639728cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "manager = DTIDatasetManager(TDCDTIWrapper(DTI(name = 'BindingDB_Kd')),\n",
    "                 MinMaxScaling(),\n",
    "                 GraphCreator(),\n",
    "                 BertProteinFeaturizer(),\n",
    "                 partition_column=\"PROTEIN_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cfe96b-8bb3-4a95-a163-ac3d93127d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dict = manager.get_proteins()\n",
    "drug_dict = manager.get_drugs()\n",
    "train, test, val = manager.get_partition(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a004d425-d5d1-4e65-bd1d-04f822f6353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TorchProteinsGraphsDataset(train, drug_dict, protein_dict)\n",
    "test_dataset = TorchProteinsGraphsDataset(val, drug_dict, protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b29fe14-e377-476a-bd89-9db8868c84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 128,\n",
    "                                               collate_fn = torch_geometric.data.Batch.from_data_list,\n",
    "                                               shuffle=True,\n",
    "                                              num_workers = 16)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 128,\n",
    "                                               collate_fn = torch_geometric.data.Batch.from_data_list, num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89ce899-02b2-4320-995d-82f2800a6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinConvPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 init_dim = 1024,\n",
    "                 hidden_dim = 512,\n",
    "                 output_dim = 256,\n",
    "                 n_groups = 8,\n",
    "                 p_dropout_1 = 0.4,\n",
    "                 p_dropout_2 = 0.4):\n",
    "        super().__init__()\n",
    "        self.conv_attn = nn.Sequential(nn.Conv1d(in_channels = init_dim,\n",
    "                                                 out_channels=hidden_dim,\n",
    "                                                 kernel_size = 6,\n",
    "                                                 padding=\"same\",\n",
    "                                                 groups = n_groups),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(p_dropout_1),\n",
    "              nn.Conv1d(in_channels = hidden_dim,\n",
    "                        out_channels=1,\n",
    "                        kernel_size = 1,\n",
    "                        stride = 1),)\n",
    "        self.conv_seq = nn.Sequential(nn.Conv1d(in_channels = init_dim,\n",
    "                                                out_channels=hidden_dim,\n",
    "                                                kernel_size = 6,\n",
    "                                                padding=\"same\",\n",
    "                                                groups = n_groups),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(p_dropout_2),\n",
    "              nn.Conv1d(in_channels = hidden_dim, out_channels=output_dim, kernel_size = 1, stride = 1),)\n",
    "    def forward(self, x):\n",
    "        a =  (self.conv_attn(x.transpose(1, 2)).squeeze()).softmax(-1)\n",
    "        v = self.conv_seq(x.transpose(1, 2)).squeeze().transpose(1, 2)\n",
    "        return a.unsqueeze(-1).mul(v).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108c6dfd-10f6-4dfd-9c63-c7ba93f04bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNAttnDrugPooling(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim,\n",
    "                 hidden_dim,\n",
    "                 output_embed_dim,\n",
    "                 p_dropout_attn = 0.0,\n",
    "                 p_dropout_nodes = 0.0,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pool = gnn.GlobalAttention(nn.Sequential(nn.Linear(embed_dim, hidden_dim),\n",
    "                                                             nn.ReLU(),\n",
    "                                                             nn.Dropout(p_dropout_attn),\n",
    "                                                             nn.Linear(hidden_dim, 1),\n",
    "                                                             AttnDropout(p_dropout_nodes)),\n",
    "                                               nn.Sequential(nn.Linear(embed_dim, hidden_dim),\n",
    "                                                             nn.ReLU(),\n",
    "                                                             nn.Dropout(p_dropout_attn),\n",
    "                                                             nn.Linear(hidden_dim, output_embed_dim)))\n",
    "    def set_cold(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad=False\n",
    "    def forward(self, x, batch):\n",
    "        return self.pool(x, batch)\n",
    "class GNNEncoderDecoder(PairsNetwork):\n",
    "    def __init__(self,\n",
    "                 protein_encoder,\n",
    "                 drug_encoder,\n",
    "                 protein_adapter,\n",
    "                 drug_adapter,\n",
    "                 decoder,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Network consisting of two encoders, two adapters and a decoder.\n",
    "        The forward method has to be reimplemented.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.protein_encoder = protein_encoder\n",
    "        self.drug_encoder = drug_encoder\n",
    "        self.protein_adapter = protein_adapter\n",
    "        self.drug_adapter = drug_adapter\n",
    "        self.decoder = decoder\n",
    "    def forward(self, data, *args, **kwargs):\n",
    "        x_lines = self.protein_adapter(self.protein_encoder(data[\"protein\"]))\n",
    "        x_drugs = self.drug_adapter(self.drug_encoder(data[\"x\"],\n",
    "                                                      data[\"edge_index\"],\n",
    "                                                      data[\"edge_attr\"],\n",
    "                                                      data[\"batch\"]),\n",
    "                                    data[\"batch\"])\n",
    "        return self.decoder(x_lines, x_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb39bf9-4ff3-4dd2-8ec4-3a548c68743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.init_gat = gnn.GATConv(79, embed_dim, edge_dim = 10)\n",
    "        self.layers = _stack = GatedGNNRes(TransGAT,\n",
    "                                           {\"input_dim\":embed_dim,\n",
    "                                             \"output_dim\":embed_dim,\n",
    "                                             \"edge_dim\":10,\n",
    "                                             \"num_heads\":1,},\n",
    "                                           n_layers = 2)\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.init_gat(x, edge_index, edge_attr)\n",
    "        return self.layers(x, edge_index, edge_attr, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33cfab28-a71e-4b5c-a6f3-eddcf4cdf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNEncoderDecoder(protein_encoder = nn.Identity(),\n",
    "                         drug_encoder = GTEncoder(embed_dim = 256),\n",
    "                         protein_adapter = ProteinConvPooling(hidden_dim = 512, output_dim=256),\n",
    "                         drug_adapter = GNNAttnDrugPooling(embed_dim = 256, hidden_dim = 1024, output_embed_dim=256, p_dropout_attn=0.2),\n",
    "                         decoder = FCDecoder(256+256, 2048, p_dropout_2 = 0.3))\n",
    "                         #decoder = NonlinearDotDecoder(256, 1024, 64, p_dropout_1=0.3, p_dropout_2 = 0.3))\n",
    "optim = torch.optim.Adam(model.parameters(), 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience = 2, factor = 0.75)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274eacb1-982b-414d-85a8-b5a7cb500e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fc741505664b7a9003818c5c9ccc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'MeanSquaredError_test': 0.00040473032277077436,\n",
      " 'MeanSquaredError_train': 0.04489264637231827,\n",
      " 'PearsonCorrCoef_test': -0.008448257111012936,\n",
      " 'PearsonCorrCoef_train': 0.005974019877612591,\n",
      " 'R_average_test': nan,\n",
      " 'R_average_train': nan}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73615855bf4c421e9d9d635207055e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'MeanSquaredError_test': 0.0017297266749665141,\n",
      " 'MeanSquaredError_train': 0.008432043716311455,\n",
      " 'PearsonCorrCoef_test': 0.3168678283691406,\n",
      " 'PearsonCorrCoef_train': 0.09814435988664627,\n",
      " 'R_average_test': nan,\n",
      " 'R_average_train': nan}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff35b23d7a34780871c682dc1c05f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "model.to(device)\n",
    "mse = nn.MSELoss()\n",
    "metrics = torchmetrics.MetricCollection([torchmetrics.MeanSquaredError(), torchmetrics.PearsonCorrCoef()]).to(device)\n",
    "elm = ElementwiseMetric(average=\"drugs\")\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    elm.reset()\n",
    "    metrics.reset()\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "        for n_b, b in enumerate(train_dataloader):\n",
    "            if ((n_b + 1) % 10) == 0:\n",
    "                pbar.update(10)\n",
    "            b = b.to(device)\n",
    "            y_pred = model(b)\n",
    "            l = mse(y_pred.squeeze(), b[\"y\"].squeeze())\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "            with torch.no_grad():\n",
    "                metrics.update(y_pred.squeeze(), b[\"y\"].squeeze())\n",
    "                elm.update(y_pred.squeeze(), b[\"y\"].squeeze(), b[\"DRUG_ID\"], b[\"PROTEIN_ID\"])\n",
    "            optim.zero_grad()\n",
    "    metric_dict_train = {it[0] + \"_train\":it[1].cpu().item() for it in metrics.compute().items()}\n",
    "    metric_dict_train[\"R_average_train\"] = elm.compute().item()\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    elm.reset()\n",
    "    scheduler.step(metric_dict_train[\"MeanSquaredError_train\"])\n",
    "    with torch.no_grad():\n",
    "        for b in test_dataloader:\n",
    "            b = b.to(device)\n",
    "            y_pred = model(b)\n",
    "            metrics.update(y_pred.squeeze(), b[\"y\"].squeeze())\n",
    "            elm.update(y_pred.squeeze(), b[\"y\"].squeeze(), b[\"DRUG_ID\"], b[\"PROTEIN_ID\"])\n",
    "    metric_dict_test = {it[0] + \"_test\":it[1].cpu().item() for it in metrics.compute().items()}\n",
    "    metric_dict_train[\"R_average_test\"] = elm.compute().item()\n",
    "    metric_dict = {**metric_dict_test, **metric_dict_train}\n",
    "    print(epoch)\n",
    "    pprint(metric_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi_python",
   "language": "python",
   "name": "mpi_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
